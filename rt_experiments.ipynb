{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "ym4Naw1SY5XT",
    "outputId": "2fd1ad07-e51c-4e20-cc74-7db4cd6a92fe",
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (4.46.3)\n",
      "Collecting transformers\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/d0/a7/7eedcf6a359e1e1eff3bc204ad022485aa5d88c08e1e3e0e0aee8a2e2235/transformers-4.47.0-py3-none-any.whl.metadata\n",
      "  Using cached transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: datasets in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (3.1.0)\n",
      "Requirement already satisfied: evaluate in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (0.4.3)\n",
      "Requirement already satisfied: nltk in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (3.9.1)\n",
      "Requirement already satisfied: accelerate in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (1.2.0)\n",
      "Requirement already satisfied: trl in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (0.12.2)\n",
      "Requirement already satisfied: wandb in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (0.19.0)\n",
      "Requirement already satisfied: peft in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (0.14.0)\n",
      "Requirement already satisfied: rouge_score in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (0.1.2)\n",
      "Requirement already satisfied: filelock in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Obtaining dependency information for tokenizers<0.22,>=0.21 from https://files.pythonhosted.org/packages/22/06/69d7ce374747edaf1695a4f61b83570d91cc8bbfc51ccfecf76f56ab4aac/tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: xxhash in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: click in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: psutil in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from accelerate) (2.1.0+cu118)\n",
      "Requirement already satisfied: rich in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from trl) (13.9.4)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: eval-type-backport in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from wandb) (0.2.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from wandb) (3.10.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.15.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from wandb) (4.24.4)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from wandb) (2.10.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from wandb) (2.19.0)\n",
      "Requirement already satisfied: setproctitle in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: setuptools in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from wandb) (68.0.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: absl-py in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from rouge_score) (2.0.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from pydantic<3,>=2.6->wandb) (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: sympy in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from rich->trl) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from rich->trl) (2.15.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U transformers datasets evaluate nltk accelerate trl wandb peft rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BPa5JXdC1Gpv"
   },
   "outputs": [],
   "source": [
    "update_interval = 10\n",
    "num_token = 5\n",
    "memory_len = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6nS1EpEjZSds"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 00:47:43.088275: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-07 00:47:43.763896: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, T5ForConditionalGeneration, T5Config, logging\n",
    "import torch\n",
    "from custom_model import RTModel, CustomTrainer\n",
    "import os\n",
    "import logging as sys_logging\n",
    "\n",
    "sys_logging.captureWarnings(True)\n",
    "logger = sys_logging.getLogger(\"transformers.trainer\")\n",
    "class LogFilter(sys_logging.Filter):\n",
    "    def filter(self, record):\n",
    "        message = record.getMessage()\n",
    "        return \"deprecated\" not in message and \"hang\" not in message\n",
    "logger.addFilter(LogFilter())\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"  # Dealing with HF logging bugs\n",
    "\n",
    "model_name = \"google/flan-t5-base\"\n",
    "\n",
    "embed_dim = T5Config.from_pretrained(model_name).d_model\n",
    "\n",
    "model = RTModel.from_pretrained(model_name, num_token=num_token)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model.config.max_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hp1ACHlQZVBX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max output token number: 257\n",
      "Dataset({\n",
      "    features: ['context', 'statement', 'reasoning', 'depth', 'flag', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 1000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "train_dataset = load_dataset(\"Jise/ruletaker\", split=\"train\")\n",
    "test_dataset = load_dataset(\"Jise/ruletaker\", split=\"test\")\n",
    "ood_dataset = load_dataset(\"Jise/ruletaker\", split=\"ood_test\")\n",
    "\n",
    "prompt = \"Based on the facts and rules, first think step by step and give simple reasoning steps citing the rules, and then output whether the assertion is true by true or false.\"\n",
    "\n",
    "temp = tokenizer(train_dataset[\"reasoning\"])\n",
    "print(\"Max output token number:\", max([len(s) for s in temp[\"input_ids\"]]))\n",
    "\n",
    "def preprocess(examples):\n",
    "    inputs = [prompt + \"Assertion:\" + x for x in examples[\"context\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=511, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    labels = [x + \"\\nThe answer is \" + y for x, y in zip(examples[\"reasoning\"], examples[\"flag\"])]\n",
    "    labels = tokenizer(text_target=labels, max_length=262, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess, batched=True)\n",
    "ood_dataset = ood_dataset.map(preprocess, batched=True)\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LoANhIXeZdL2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiseshen\u001b[0m (\u001b[33mjise\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/idies/.netrc\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "import requests\n",
    "import pickle\n",
    "import torch\n",
    "import wandb\n",
    "import nltk\n",
    "import evaluate\n",
    "\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"punkt_tab\", quiet=True)\n",
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "run_name = \"Flan-T5_RuleTaker_RT\"\n",
    "\n",
    "with open(\"TOKENS.pkl\", \"rb\") as f:\n",
    "    TOKENS = pickle.load(f)\n",
    "\n",
    "WANDB_TOKEN = TOKENS[\"WANDB_TOKEN\"]\n",
    "HF_TOKEN = TOKENS[\"HF_TOKEN\"]\n",
    "\n",
    "wandb.login(key=WANDB_TOKEN)\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in labels]\n",
    " \n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    result[\"acc\"] = np.mean([(\"true\" in label.lower() and \"true\" in pred.lower()) or (\"false\" in label.lower() and \"false\" in pred.lower()) for pred, label in zip(preds, labels)])\n",
    "    \n",
    "    return result\n",
    "    \n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "sft_training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./flan-t5-rt-ruletaker\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=300,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=300,\n",
    "    save_total_limit=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    label_smoothing_factor=1e-5,\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=5,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    weight_decay=0.01,\n",
    "    bf16=True,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=256,\n",
    "    push_to_hub=True,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=run_name,\n",
    "    hub_token=HF_TOKEN,\n",
    "    hub_model_id=\"Jise/flan-t5-ruletaker-rt\",\n",
    "    save_safetensors=False,\n",
    ")\n",
    "\n",
    "rt_trainer = CustomTrainer(\n",
    "    update_interval=update_interval,\n",
    "    memory_len=memory_len,\n",
    "    model=model,\n",
    "    args=sft_training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset={\"test\": test_dataset, \"ood\": ood_dataset},\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "id": "4AmUFu9HU8P-",
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/idies/workspace/Temporary/JiseShen/scratch/wandb/run-20241207_004756-p07ddq4k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jise/huggingface/runs/p07ddq4k' target=\"_blank\">Flan-T5_RuleTaker_RT</a></strong> to <a href='https://wandb.ai/jise/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jise/huggingface' target=\"_blank\">https://wandb.ai/jise/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jise/huggingface/runs/p07ddq4k' target=\"_blank\">https://wandb.ai/jise/huggingface/runs/p07ddq4k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 1:04:56, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Test Rouge1</th>\n",
       "      <th>Test Rouge2</th>\n",
       "      <th>Test Rougel</th>\n",
       "      <th>Test Rougelsum</th>\n",
       "      <th>Test Acc</th>\n",
       "      <th>Ood Loss</th>\n",
       "      <th>Ood Rouge1</th>\n",
       "      <th>Ood Rouge2</th>\n",
       "      <th>Ood Rougel</th>\n",
       "      <th>Ood Rougelsum</th>\n",
       "      <th>Ood Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>No log</td>\n",
       "      <td>50.180489</td>\n",
       "      <td>0.230879</td>\n",
       "      <td>0.144393</td>\n",
       "      <td>0.218862</td>\n",
       "      <td>0.224500</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>38.539150</td>\n",
       "      <td>0.297880</td>\n",
       "      <td>0.185867</td>\n",
       "      <td>0.275606</td>\n",
       "      <td>0.288075</td>\n",
       "      <td>0.058667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>No log</td>\n",
       "      <td>39.190765</td>\n",
       "      <td>0.190051</td>\n",
       "      <td>0.128402</td>\n",
       "      <td>0.175926</td>\n",
       "      <td>0.189851</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>34.519337</td>\n",
       "      <td>0.220282</td>\n",
       "      <td>0.147778</td>\n",
       "      <td>0.195363</td>\n",
       "      <td>0.218153</td>\n",
       "      <td>0.194667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "WARNING:py.warnings:/home/idies/miniconda3/envs/py39/lib/python3.9/site-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 256}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=625, training_loss=0.05504026737213135, metrics={'train_runtime': 3899.1849, 'train_samples_per_second': 1.282, 'train_steps_per_second': 0.16, 'total_flos': 1885790039040000.0, 'train_loss': 0.05504026737213135, 'epoch': 5.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT Test Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 20:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_test_loss': 39.73509216308594,\n",
       " 'eval_test_rouge1': 0.1933269292162502,\n",
       " 'eval_test_rouge2': 0.1294599170243153,\n",
       " 'eval_test_rougeL': 0.17894140530366087,\n",
       " 'eval_test_rougeLsum': 0.1925948014545385,\n",
       " 'eval_test_acc': 0.16,\n",
       " 'eval_test_runtime': 507.5324,\n",
       " 'eval_test_samples_per_second': 0.493,\n",
       " 'eval_test_steps_per_second': 0.032,\n",
       " 'epoch': 5.0,\n",
       " 'eval_ood_loss': 35.09615707397461,\n",
       " 'eval_ood_rouge1': 0.21526193488292422,\n",
       " 'eval_ood_rouge2': 0.1444443530901435,\n",
       " 'eval_ood_rougeL': 0.19240451977751177,\n",
       " 'eval_ood_rougeLsum': 0.2123844494270246,\n",
       " 'eval_ood_acc': 0.168,\n",
       " 'eval_ood_runtime': 742.4027,\n",
       " 'eval_ood_samples_per_second': 0.505,\n",
       " 'eval_ood_steps_per_second': 0.032}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"RT Test Results:\")\n",
    "rt_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9 (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
