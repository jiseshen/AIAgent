{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.45.2 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (4.45.2)\n",
      "Requirement already satisfied: datasets in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (3.1.0)\n",
      "Requirement already satisfied: evaluate in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (0.4.3)\n",
      "Requirement already satisfied: nltk in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (3.9.1)\n",
      "Requirement already satisfied: accelerate in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (1.2.0)\n",
      "Requirement already satisfied: wandb in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (0.19.0)\n",
      "Requirement already satisfied: rouge_score in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (0.1.2)\n",
      "Requirement already satisfied: filelock in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from transformers==4.45.2) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from transformers==4.45.2) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from transformers==4.45.2) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from transformers==4.45.2) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from transformers==4.45.2) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from transformers==4.45.2) (2022.7.9)\n",
      "Requirement already satisfied: requests in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from transformers==4.45.2) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from transformers==4.45.2) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from transformers==4.45.2) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from transformers==4.45.2) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: xxhash in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: click in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: psutil in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from accelerate) (2.1.0+cu118)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: eval-type-backport in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from wandb) (0.2.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from wandb) (3.10.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.15.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from wandb) (4.24.4)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from wandb) (2.10.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from wandb) (2.19.0)\n",
      "Requirement already satisfied: setproctitle in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: setuptools in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from wandb) (68.0.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: absl-py in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from rouge_score) (2.0.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from pydantic<3,>=2.6->wandb) (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from requests->transformers==4.45.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from requests->transformers==4.45.2) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from requests->transformers==4.45.2) (2023.7.22)\n",
      "Requirement already satisfied: sympy in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U transformers==4.45.2 datasets evaluate nltk accelerate wandb rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3C29d4hgqEuM"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"google/flan-t5-base\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model.config.max_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QyCrybL8qNwg",
    "outputId": "994950e9-9d1b-420a-87c0-9ba3d033c159"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max output token number: 257\n",
      "Dataset({\n",
      "    features: ['context', 'statement', 'reasoning', 'depth', 'flag', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 1000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "train_dataset = load_dataset(\"Jise/ruletaker\", split=\"train\")\n",
    "test_dataset = load_dataset(\"Jise/ruletaker\", split=\"test\")\n",
    "ood_dataset = load_dataset(\"Jise/ruletaker\", split=\"ood_test\")\n",
    "\n",
    "prompt = \"Based on the facts and rules, first think step by step and give simple reasoning steps citing the rules, and then output whether the assertion is true by true or false.\"\n",
    "\n",
    "temp = tokenizer(train_dataset[\"reasoning\"])\n",
    "print(\"Max output token number:\", max([len(s) for s in temp[\"input_ids\"]]))\n",
    "\n",
    "def preprocess(examples):\n",
    "    inputs = [prompt + \"Assertion:\" + x for x in examples[\"context\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=511, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    labels = [x + \"\\nThe answer is \" + y for x, y in zip(examples[\"reasoning\"], examples[\"flag\"])]\n",
    "    labels = tokenizer(text_target=labels, max_length=262, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess, batched=True)\n",
    "ood_dataset = ood_dataset.map(preprocess, batched=True)\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "81714658b31143d89b55248848673c9b",
      "7e56be4f4deb4fafa11470e13e725744",
      "d6c2c3e938dd4fbe853c3fadc2e9a230",
      "3f2dfe2e1e674ecd97a797a22682daf1",
      "a061d8e27af5468fb4ca65051e514c5e",
      "7edc6c651462409fa6107180c1ad7195",
      "d08422e1b3cd49779e07f1e6a5dfb261",
      "f44ab31f6b9749f7a1e4f65bd779133f",
      "8e1a01cee4d649bc8054f651bbc52783",
      "74ef6bdb52c7479eb8fdc37c9a368ebb",
      "29838887566d48198ef6f2ced34225e8"
     ]
    },
    "id": "EqpbWWqubeQO",
    "outputId": "4280179b-7115-4f97-83ee-2dc4d660d8fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 21:48:21.767950: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-05 21:48:22.393434: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiseshen\u001b[0m (\u001b[33mjise\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/idies/.netrc\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "from trl import DPOTrainer, DPOConfig\n",
    "from trl.trainer.utils import SIMPLE_CHAT_TEMPLATE\n",
    "import requests\n",
    "import pickle\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "import wandb\n",
    "import nltk\n",
    "import evaluate\n",
    "\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"punkt_tab\", quiet=True)\n",
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "run_name = \"Flan-T5_RuleTaker_SFT\"\n",
    "\n",
    "with open(\"TOKENS.pkl\", \"rb\") as f:\n",
    "    TOKENS = pickle.load(f)\n",
    "\n",
    "WANDB_TOKEN = TOKENS[\"WANDB_TOKEN\"]\n",
    "HF_TOKEN = TOKENS[\"HF_TOKEN\"]\n",
    "\n",
    "wandb.login(key=WANDB_TOKEN)\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in labels]\n",
    " \n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    result[\"acc\"] = np.mean([(\"true\" in label.lower() and \"true\" in pred.lower()) or (\"false\" in label.lower() and \"false\" in pred.lower()) for pred, label in zip(preds, labels)])\n",
    "    \n",
    "    return result\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "sft_training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./flan-t5-sft-ruletaker\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=2,\n",
    "    gradient_checkpointing=True,\n",
    "    label_smoothing_factor=1e-5,\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=5,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    bf16=True,\n",
    "    predict_with_generate=True,\n",
    "    push_to_hub=True,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=run_name,\n",
    "    hub_token=HF_TOKEN,\n",
    "    hub_model_id=\"Jise/flan-t5-ruletaker-sft\",\n",
    "    save_safetensors=False,\n",
    ")\n",
    "\n",
    "sft_trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=sft_training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot Test result:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idies/miniconda3/envs/py39/lib/python3.9/site-packages/transformers/generation/utils.py:1338: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 02:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/idies/workspace/Temporary/JiseShen/scratch/wandb/run-20241205_214843-83zxy7xk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jise/huggingface/runs/83zxy7xk' target=\"_blank\">Flan-T5_RuleTaker_SFT</a></strong> to <a href='https://wandb.ai/jise/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jise/huggingface' target=\"_blank\">https://wandb.ai/jise/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jise/huggingface/runs/83zxy7xk' target=\"_blank\">https://wandb.ai/jise/huggingface/runs/83zxy7xk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 36.28911209106445,\n",
       " 'eval_model_preparation_time': 0.0048,\n",
       " 'eval_rouge1': 0.018774714781507364,\n",
       " 'eval_rouge2': 0.0,\n",
       " 'eval_rougeL': 0.018716265665975895,\n",
       " 'eval_rougeLsum': 0.018794678105219717,\n",
       " 'eval_acc': 0.492,\n",
       " 'eval_runtime': 14.8611,\n",
       " 'eval_samples_per_second': 16.822,\n",
       " 'eval_steps_per_second': 1.077}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Zero-shot Test result:\")\n",
    "sft_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot OOD result:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 22.32184410095215,\n",
       " 'eval_model_preparation_time': 0.0048,\n",
       " 'eval_rouge1': 0.007528396075322917,\n",
       " 'eval_rouge2': 0.0,\n",
       " 'eval_rougeL': 0.007524591822213361,\n",
       " 'eval_rougeLsum': 0.007532277095522594,\n",
       " 'eval_acc': 0.42933333333333334,\n",
       " 'eval_runtime': 20.6375,\n",
       " 'eval_samples_per_second': 18.171,\n",
       " 'eval_steps_per_second': 1.163}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Zero-shot OOD result:\")\n",
    "sft_trainer.evaluate(eval_dataset=ood_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='626' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 16:21, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.593000</td>\n",
       "      <td>0.114167</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.506817</td>\n",
       "      <td>0.394937</td>\n",
       "      <td>0.446455</td>\n",
       "      <td>0.490164</td>\n",
       "      <td>0.624000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.111400</td>\n",
       "      <td>0.074364</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.572086</td>\n",
       "      <td>0.441646</td>\n",
       "      <td>0.491652</td>\n",
       "      <td>0.562684</td>\n",
       "      <td>0.636000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>0.071179</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.566286</td>\n",
       "      <td>0.431515</td>\n",
       "      <td>0.480286</td>\n",
       "      <td>0.545394</td>\n",
       "      <td>0.624000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.079400</td>\n",
       "      <td>0.071062</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.546849</td>\n",
       "      <td>0.433400</td>\n",
       "      <td>0.473044</td>\n",
       "      <td>0.537601</td>\n",
       "      <td>0.624000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.068899</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.561883</td>\n",
       "      <td>0.439878</td>\n",
       "      <td>0.475096</td>\n",
       "      <td>0.543862</td>\n",
       "      <td>0.608000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.072800</td>\n",
       "      <td>0.068771</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.551749</td>\n",
       "      <td>0.435579</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.536157</td>\n",
       "      <td>0.616000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idies/miniconda3/envs/py39/lib/python3.9/site-packages/transformers/modeling_utils.py:2618: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 256}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sft_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFT Test result:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.06863230466842651,\n",
       " 'eval_model_preparation_time': 0.0048,\n",
       " 'eval_rouge1': 0.5405360565791885,\n",
       " 'eval_rouge2': 0.4278123695553129,\n",
       " 'eval_rougeL': 0.4657341716918304,\n",
       " 'eval_rougeLsum': 0.5253153542621036,\n",
       " 'eval_acc': 0.624,\n",
       " 'eval_runtime': 55.6622,\n",
       " 'eval_samples_per_second': 4.491,\n",
       " 'eval_steps_per_second': 0.287,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"SFT Test result:\")\n",
    "sft_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFT OOD result:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.10819105058908463,\n",
       " 'eval_model_preparation_time': 0.0048,\n",
       " 'eval_rouge1': 0.48410530695527554,\n",
       " 'eval_rouge2': 0.4000244274186455,\n",
       " 'eval_rougeL': 0.39304103134106605,\n",
       " 'eval_rougeLsum': 0.4759229556808772,\n",
       " 'eval_acc': 0.36533333333333334,\n",
       " 'eval_runtime': 75.1572,\n",
       " 'eval_samples_per_second': 4.99,\n",
       " 'eval_steps_per_second': 0.319,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"SFT OOD result:\")\n",
    "sft_trainer.evaluate(eval_dataset=ood_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9 (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "29838887566d48198ef6f2ced34225e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f2dfe2e1e674ecd97a797a22682daf1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74ef6bdb52c7479eb8fdc37c9a368ebb",
      "placeholder": "​",
      "style": "IPY_MODEL_29838887566d48198ef6f2ced34225e8",
      "value": " 2354/2354 [00:07&lt;00:00, 241.43 examples/s]"
     }
    },
    "74ef6bdb52c7479eb8fdc37c9a368ebb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e56be4f4deb4fafa11470e13e725744": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7edc6c651462409fa6107180c1ad7195",
      "placeholder": "​",
      "style": "IPY_MODEL_d08422e1b3cd49779e07f1e6a5dfb261",
      "value": "Tokenizing eval dataset: 100%"
     }
    },
    "7edc6c651462409fa6107180c1ad7195": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81714658b31143d89b55248848673c9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7e56be4f4deb4fafa11470e13e725744",
       "IPY_MODEL_d6c2c3e938dd4fbe853c3fadc2e9a230",
       "IPY_MODEL_3f2dfe2e1e674ecd97a797a22682daf1"
      ],
      "layout": "IPY_MODEL_a061d8e27af5468fb4ca65051e514c5e"
     }
    },
    "8e1a01cee4d649bc8054f651bbc52783": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a061d8e27af5468fb4ca65051e514c5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d08422e1b3cd49779e07f1e6a5dfb261": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d6c2c3e938dd4fbe853c3fadc2e9a230": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f44ab31f6b9749f7a1e4f65bd779133f",
      "max": 2354,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8e1a01cee4d649bc8054f651bbc52783",
      "value": 2354
     }
    },
    "f44ab31f6b9749f7a1e4f65bd779133f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
